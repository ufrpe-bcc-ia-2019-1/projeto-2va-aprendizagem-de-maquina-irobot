{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FakeNews.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAtocGwwyeD4",
        "colab_type": "text"
      },
      "source": [
        "# Carregar Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "romYNABdygk_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "df = pd.read_csv('train.csv')\n",
        "\n",
        "#train = pd.read_csv('train.csv')\n",
        "#test = pd.read_csv('test.csv')\n",
        "\n",
        "train, test = train_test_split(df, test_size=0.2)\n",
        "\n",
        "id_arrays = test['id'].to_numpy()\n",
        "\n",
        "results_arrays =  []\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGw3EpFEzYMD",
        "colab_type": "text"
      },
      "source": [
        "# Pré- Processamento\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcDi4TZC0emS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "from nltk.tokenize.regexp import RegexpTokenizer\n",
        "\n",
        "def preprocess(text):\n",
        "  \n",
        "  \n",
        "  \n",
        "  # converter para lowercase\n",
        "  text = str(text).lower()\n",
        "  \n",
        "  # tokenizar o texto em palavras\n",
        "  tokenizer = RegexpTokenizer(r'\\w+')\n",
        "  tokens = tokenizer.tokenize(text.lower())\n",
        "  \n",
        "  stopwords = ['a', 'about', 'above', 'after', 'again', 'against', 'all', 'am', 'an', 'and', 'any', 'are', \"aren't\", 'as', 'at',\n",
        "             'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by',  \n",
        "              'down', 'during','each', 'few', 'for', 'from', 'further', \n",
        "             'hers', 'herself', 'him', 'himself', 'his','i', \"i'd\", \"i'll\", \"i'm\", \"i've\", 'in', 'into', 'itself','1st', '2nd', '3rd','4th', '5th', '6th', '7th', '8th', '9th', '10th'\n",
        "             \"let's\", 'me', 'more', 'most', \"mustn't\", 'my', 'myself','no', 'nor', 'not', 'of', 'off', 'on', 'once', 'only', 'other', 'ought', 'our', 'ours' 'ourselves', 'out', 'over', 'own',\n",
        "             'same', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'so', 'some', 'such', \n",
        "             'than', 'that',\"that's\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', \"there's\", 'these', 'they', \"they'd\", \n",
        "             \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 'very', \n",
        "             'we', \"we'd\", \"we'll\", \"we're\", \"we've\", 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves', \n",
        "             'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten', 'hundred', 'thousand']\n",
        "\n",
        "  # filtrar palavras\n",
        "  tokens = [word for word in tokens\n",
        "           if word not in stopwords       # descartar stopwords\n",
        "                and len(word) > 2         # descartar palavras com menos de 3 caracteres\n",
        "                and not word[0].isdigit()] # descartar tokens contendo apenas numeros\n",
        "\n",
        "\n",
        "  return ' '.join(tokens)\n",
        "\n",
        "X_train = []\n",
        "for doc in train['text']:\n",
        "  X_train.append(preprocess(doc))\n",
        "  \n",
        "X_test = []\n",
        "for doc in test['text']:\n",
        "  X_test.append(preprocess(doc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CZ7toD71iGc",
        "colab_type": "text"
      },
      "source": [
        "# Term Frequency (TF)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPugao9-1lE-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(use_idf=False)\n",
        "tf_model = vectorizer.fit(X_train)\n",
        "\n",
        "X_tf_train = tf_model.transform(X_train)\n",
        "X_tf_test  = tf_model.transform(X_test)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_w4BN3joPd3M",
        "colab_type": "text"
      },
      "source": [
        "# TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOOtLPesPiBJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(use_idf=True)\n",
        "tf_model = vectorizer.fit(X_train)\n",
        "\n",
        "X_tfidf_train = tf_model.transform(X_train)\n",
        "X_tfidf_test  = tf_model.transform(X_test)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UROe1vnZIO5z",
        "colab_type": "text"
      },
      "source": [
        "# BOW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZbFTzk6IY6K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "bow_model  = vectorizer.fit(X_train)\n",
        "\n",
        "X_bow_train = bow_model.transform(X_train)\n",
        "\n",
        "X_bow_test  = bow_model.transform(X_test)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nJN9hp9hkwA",
        "colab_type": "text"
      },
      "source": [
        "# Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CYPVm5HhnRN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "clf = MultinomialNB()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmZmozDQ1lz_",
        "colab_type": "text"
      },
      "source": [
        "# Naive Bayes + TermFrequency(TF)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbFv5mqf1qT2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "0778b190-8184-4490-8a2d-6c492758b69b"
      },
      "source": [
        "clf.fit(X_tf_train,train['label'])\n",
        "\n",
        "acc = clf.score(X_tf_test , test['label'])\n",
        "\n",
        "print('Acurácia: ', acc)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acurácia:  0.8055288461538461\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oh3COSH3IcpD",
        "colab_type": "text"
      },
      "source": [
        "# Naive Bayes + BOW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vDytvf_IjOj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "fae360e3-106f-42e6-ddb4-97723b21f571"
      },
      "source": [
        "clf.fit(X_bow_train, train['label'])\n",
        "  \n",
        "acc = clf.score(X_bow_test , test['label'])\n",
        "\n",
        "print('Acurácia: ', acc)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acurácia:  0.8913461538461539\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pF5jDJYgPoIL",
        "colab_type": "text"
      },
      "source": [
        "# Naive Bayes + TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_te7RUe4Pzpi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "9e51be6a-82a6-49af-b828-afa351182669"
      },
      "source": [
        "clf.fit(X_tfidf_train, train['label'])\n",
        "\n",
        "acc = clf.score(X_tfidf_test , test['label'])\n",
        "\n",
        "print('Acurácia: ', acc)\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acurácia:  0.8574519230769231\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-QC38FgitkH",
        "colab_type": "text"
      },
      "source": [
        "# Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PfTxjUbiw_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "RSEED = 50\n",
        "\n",
        "# Create the model with 100 trees\n",
        "model = RandomForestClassifier(n_estimators=100, \n",
        "                               random_state=RSEED, \n",
        "                               max_features = 'sqrt',\n",
        "                               n_jobs=-1, verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MdCVOLOgfTQ",
        "colab_type": "text"
      },
      "source": [
        "# Random Forest + TF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGvBhb-Pgqz2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "008cc946-5e62-4545-d816-7a55def20556"
      },
      "source": [
        "# Fit on training data\n",
        "model.fit(X_tf_train, train['label'])\n",
        "\n",
        "acc = model.score(X_tf_test , test['label'])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   21.8s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   46.7s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.7s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrqyRHCsjP45",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "7f3f8014-9cff-4362-9a5b-5cf246545d9a"
      },
      "source": [
        "print('Acurácia: ', acc)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acurácia:  0.9117788461538462\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGVCxmbegs5U",
        "colab_type": "text"
      },
      "source": [
        "# Random Forest + BOW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBvNW0V-gwzG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "fb6485f4-a9ac-4820-a5e8-edef756ead18"
      },
      "source": [
        "# Fit on training data\n",
        "model.fit(X_bow_train, train['label'])\n",
        "\n",
        "acc = model.score(X_bow_test , test['label'])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   23.7s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   50.5s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.4s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.7s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDN3X9V6i_gz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "472ad4c3-bc80-4508-83cc-ba136861c2c1"
      },
      "source": [
        "print('Acurácia: ', acc)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acurácia:  0.9064903846153847\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDzhV6qYgxKh",
        "colab_type": "text"
      },
      "source": [
        "# Random Forest + TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkxNUsDDg1zo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "1bb90f2d-9d7c-461b-ab59-b59148dd9ac4"
      },
      "source": [
        "# Fit on training data\n",
        "model.fit(X_tfidf_train, train['label'])\n",
        "\n",
        "acc = model.score(X_tfidf_test , test['label'])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   21.4s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   45.9s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.4s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.8s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZVnmIrqjRBx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "29f227e9-98d4-46cf-aec4-110576c7436a"
      },
      "source": [
        "print('Acurácia: ', acc)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acurácia:  0.9122596153846154\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}